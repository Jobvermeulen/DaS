{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification assignment | Statistics 3\n",
    "Author: **616184**<br>\n",
    "Student number: **616184**<br>\n",
    "Date: **29-06-2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using this notebook, you need to install some packages. There're two options to install these, via pip install and via anaconda dashboard.\n",
    "The following packages should be installed:\n",
    "\n",
    "* numpy\n",
    "* pandas\n",
    "* scikit-learn\n",
    "* xgboost\n",
    "* matplotlib\n",
    "* ipywidgets\n",
    "* decision-tree-id3\n",
    "\n",
    "From these we will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits import mplot3d\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from id3 import Id3Estimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Data\n",
    "We are going to use the datafile income_evalution from kaggle. This contains data about income from a selection of people from all over the world. We are going to use the following columns:age, workclass, education, maritual-status, relationship, race, native-country and income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load income csv with the pd.read_csv\n",
    "incomeCSV = pd.read_csv('data/income_evaluation.csv',',', names=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomeCSV.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use some columns. We divide these columns in the x and y. In the x columns come all the indepent variables. In the y column i want the depent varaible. In this case, all of the the x variables are age, workclass, education, maritual-status, relationship, race, native-country. And the y variable is income. \n",
    "\n",
    "Some of the x varaibles are non numeric values. Therefore we need to categorize these, to create numeric categories.\n",
    "We do this via pd.categorical(incomeCSV['name of value']). &\n",
    "incomeCSV['name of value'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that returns the different categories in the y variable.\n",
    "incomeCSV[\"workclass\"] = pd.Categorical(incomeCSV[\"workclass\"])\n",
    "incomeCSV[\"education\"] = pd.Categorical(incomeCSV[\"education\"])\n",
    "incomeCSV[\"marital-status\"] = pd.Categorical(incomeCSV[\"marital-status\"])\n",
    "incomeCSV[\"relationship\"] = pd.Categorical(incomeCSV[\"relationship\"])\n",
    "incomeCSV[\"race\"] = pd.Categorical(incomeCSV[\"race\"])\n",
    "incomeCSV['native-country'] = pd.Categorical(incomeCSV['native-country'])\n",
    "incomeCSV[\"income\"] = pd.Categorical(incomeCSV[\"income\"])\n",
    "\n",
    "incomeCSV['workclass'] = incomeCSV[\"workclass\"].cat.codes\n",
    "incomeCSV['education'] = incomeCSV[\"education\"].cat.codes\n",
    "incomeCSV['marital-status'] = incomeCSV[\"marital-status\"].cat.codes\n",
    "incomeCSV['relationship'] = incomeCSV[\"relationship\"].cat.codes\n",
    "incomeCSV['race'] =  incomeCSV[\"race\"].cat.codes\n",
    "incomeCSV['native-country'] = incomeCSV['native-country'].cat.codes\n",
    "incomeCSV['income'] = incomeCSV['income'].cat.codes\n",
    "\n",
    "X = incomeCSV[[\"age\",\"workclass\",\"education\",\"marital-status\",\"relationship\",\"race\",\"native-country\"]]\n",
    "Y = incomeCSV[\"income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train and test our model, we need to create train and test data.\n",
    "We do this by splitting the data via train_test_split() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to split data in training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size:  32561\n",
      "Predicted test set size (40%):  6512.200000000001\n",
      "Actual test set size 6513\n"
     ]
    }
   ],
   "source": [
    "print(\"Original size: \", X.shape[0])\n",
    "print(\"Predicted test set size (40%): \", 0.2*X.shape[0])\n",
    "print(\"Actual test set size\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Basic Classification Models\n",
    "\n",
    "To predict some values we're going to create some predictions on some dummy classifiers. This creates a baseline we were can reflect to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use multiple classifiers,\n",
    "- most_frequent\n",
    "- stratified\n",
    "- prior\n",
    "- uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier most frequent:\n",
      "accuracy: 0.7669276830953478\n",
      "confusion matrix: [[4995    0]\n",
      " [1518    0]]\n",
      "\n",
      "Dummy classifier stratified:\n",
      "accuracy: 0.63841547673883\n",
      "confusion matrix: [[3798 1197]\n",
      " [1158  360]]\n",
      "\n",
      "Dummy classifier prior:\n",
      "accuracy: 0.7669276830953478\n",
      "confusion matrix: [[4995    0]\n",
      " [1518    0]]\n",
      "\n",
      "Dummy classifier uniform:\n",
      "accuracy: 0.4956241363426992\n",
      "confusion matrix: [[2487 2508]\n",
      " [ 777  741]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_trainScaled = scaler.transform(X_train)\n",
    "X_testScaled = scaler.transform(X_test)\n",
    "\n",
    "print('Dummy classifier most frequent:')\n",
    "dumMF = DummyClassifier(strategy='most_frequent')\n",
    "dumMF = dumMF.fit(X_trainScaled, Y_train)\n",
    "Y_pred = dumMF.predict(X_testScaled)\n",
    "print('accuracy:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('confusion matrix:',confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('\\nDummy classifier stratified:')\n",
    "# Dummy classifier with stratified method\n",
    "dumSrat = DummyClassifier(strategy=\"stratified\")\n",
    "dumSrat = dumSrat.fit(X_trainScaled, Y_train)\n",
    "Y_pred = dumSrat.predict(X_testScaled)\n",
    "print('accuracy:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('confusion matrix:',confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('\\nDummy classifier prior:')\n",
    "dumPrior = DummyClassifier(strategy=\"prior\")\n",
    "dumPrior.fit(X_trainScaled, Y_train)\n",
    "Y_pred = dumPrior.predict(X_testScaled)\n",
    "print('accuracy:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('confusion matrix:',confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('\\nDummy classifier uniform:')\n",
    "dumUni = DummyClassifier(strategy=\"uniform\")\n",
    "dumUni.fit(X_trainScaled, Y_train)\n",
    "Y_pred = dumUni.predict(X_testScaled)\n",
    "print('accuracy:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('confusion matrix:',confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\<explain all the results. What do the numbers mean?>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, those are our 'baseline'. A model should be dable to at least outperform these.\n",
    "\n",
    "Lets dive in..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Naive Bayes\n",
    "\n",
    "The first model discussed was the Naive Bayes model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create and fit this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussNB = GaussianNB()\n",
    "gaussNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to measure its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7762935667127284\n",
      "confusion matrix: [[4087  908]\n",
      " [ 549  969]]\n"
     ]
    }
   ],
   "source": [
    "# code to show its accuracy score AND confusion matrix.\n",
    "Y_pred = gaussNB.predict(X_test)\n",
    "print('accuracy score:', metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('confusion matrix:', confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model allready outperforms the dummy classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also have a look at what a prediction would be. We can test this with the x_test dataset. The outcome shows us how much percent was wrong during the prediction and how much was right. [[wrong percentage , right percentage ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2699136 , 0.7300864 ],\n",
       "       [0.95677576, 0.04322424],\n",
       "       [0.42610518, 0.57389482],\n",
       "       ...,\n",
       "       [0.21278805, 0.78721195],\n",
       "       [0.82428101, 0.17571899],\n",
       "       [0.60099442, 0.39900558]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about it for NB. A nice thing about NB is that it doesn't really require any parameters. Lets look at our next technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Support Vector Machines\n",
    "The second model discussed were Support Vector Machines. There is a plural here, because we can use different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic kernel is the linear one, so we'll attempt that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7669276830953478\n",
      "matrix confusion: [[4995    0]\n",
      " [1518    0]]\n"
     ]
    }
   ],
   "source": [
    "SVMLIN = SVC(kernel='linear')\n",
    "SVMLIN.fit(X_train, Y_train)\n",
    "Y_pred = SVMLIN.predict(X_test)\n",
    "\n",
    "print('accuracy score:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('matrix confusion:',confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\<explain all the results. What do the numbers mean? How is this compared to the dummy classifiers, and the NB?>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same Support Vector Machines model but with a different kernel. We are using the rbf kernel, poly kernel and sigmoid kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc with rbf kernel\n",
      "accuracy score: 0.7669276830953478\n",
      "matrix confusion: [[4995    0]\n",
      " [1518    0]]\n",
      "\n",
      "scv with poly kernel\n",
      "accuracy score: 0.7669276830953478\n",
      "matrix confusion: [[4995    0]\n",
      " [1518    0]]\n",
      "\n",
      "scv with sigmoid kernel\n",
      "accuracy score: 0.5641025641025641\n",
      "matrix confusion: [[3567 1428]\n",
      " [1411  107]]\n"
     ]
    }
   ],
   "source": [
    "print('svc with rbf kernel')\n",
    "SVMRBF = SVC(kernel='rbf')\n",
    "SVMRBF.fit(X_train, Y_train)\n",
    "Y_pred = SVMRBF.predict(X_test)\n",
    "print('accuracy score:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('matrix confusion:',confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('\\nscv with poly kernel')\n",
    "SVMPOLY = SVC(kernel='poly')\n",
    "SVMPOLY.fit(X_train, Y_train)\n",
    "Y_pred = SVMPOLY.predict(X_test)\n",
    "print('accuracy score:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('matrix confusion:',confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('\\nscv with sigmoid kernel')\n",
    "SVMSIGM = SVC(kernel='sigmoid')\n",
    "SVMSIGM.fit(X_train, Y_train)\n",
    "Y_pred = SVMSIGM.predict(X_test)\n",
    "print('accuracy score:',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('matrix confusion:',confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the top two kernels have excactly the same accuracy values (better than the dummy's). But the simoid kernel is a bit on the low side. \n",
    "\n",
    "Allright, lets move on to the third technique..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. K-Nearest Neighbors\n",
    "The third technique is the K-Nearest Neighbors (KNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this we need to do some additional steps.\n",
    "\n",
    "First we need to normalize our x variables. We do this via the standardScaler.\n",
    "This model requires a value, the n_neighbors. We need to set this, therefore we use the value '2'. Later we calculate the value by the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7970213419315215\n",
      "confusion matrix: [[4668  327]\n",
      " [ 995  523]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Convert the train and test X values, using the same scaler (so based on the X_train)\n",
    "X_trainScaled = scaler.transform(X_train)\n",
    "X_testScaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_trainScaled, Y_train)\n",
    "Y_pred = knn.predict(X_testScaled)\n",
    "print('accuracy score:', metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('confusion matrix:', confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we need to determine how many neighbors (k) we want. To do this we'll visualize the results using different values for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code to create the graph with Error Rate vs. K-values.\n",
    "error_rate=[]\n",
    "for i in range(1,100):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_trainScaled, Y_train)\n",
    "    pred_i = knn.predict(X_testScaled)\n",
    "    error_rate.append(np.mean(pred_i != Y_test))\n",
    "    \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that during this graph, the error rate decreases (which is good), but also increases (which is not to good). We need the lowest error rate, this is 79. With this error rate we get the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what we want k to be, we can create the model. With as n-neighbors as 79;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8217411331183786\n",
      "confusion matrix: [[4583  412]\n",
      " [ 749  769]]\n"
     ]
    }
   ],
   "source": [
    "# code to create the model with the selected k\n",
    "# Setup and fit the model (we use the same data as before)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=79)\n",
    "knn.fit(X_trainScaled, Y_train)\n",
    "Y_pred = knn.predict(X_testScaled)\n",
    "print('accuracy score:', metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('confusion matrix:', confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this accuracy is 82 percent. This is much higher than our dummy classifiers. The reason behind this is we choose the right amount of neighbours. This models is customized for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more basic technique to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Decision Trees\n",
    "The decision trees are also a way to create a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\<explain briefly in your own words how a Decision Tree method works>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing the following models:\n",
    "\n",
    "* ID3 (or entropy with sklearn)\n",
    "* Gini\n",
    "* Random Forest\n",
    "* Extra trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799324428066943\n",
      "[[4442  553]\n",
      " [ 754  764]]\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier package with entropy criterion\n",
    "\n",
    "entropy = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "entropy.fit(X_trainScaled,Y_train)\n",
    "Y_pred = entropy.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already one of the higher accuracy values. But not as high as k-nearest neighbour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7924151696606786\n",
      "[[4284  711]\n",
      " [ 641  877]]\n"
     ]
    }
   ],
   "source": [
    "#Id3 package\n",
    "\n",
    "id3 = Id3Estimator()\n",
    "id3.fit(X_trainScaled, Y_train)\n",
    "Y_pred = id3.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit lower, but the values look quite the same as the descisiontreeclassifier with the entropy criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7961001074773529\n",
      "[[4425  570]\n",
      " [ 758  760]]\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier package with gini criterion\n",
    "\n",
    "gini = DecisionTreeClassifier(criterion = \"gini\")\n",
    "gini.fit(X_trainScaled,Y_train)\n",
    "Y_pred = gini.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is really close to the id3estimator, but not as high as the k-nearest neighbour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\<explain all the results. What do the numbers mean? How is this compared to the dummy classifiers, the NB, the SVM kernels, and the knn?>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8134500230308613\n",
      "[[4478  517]\n",
      " [ 698  820]]\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier package\n",
    "\n",
    "RandomForest = RandomForestClassifier(random_state=0)\n",
    "RandomForestModel = RandomForest.fit(X_trainScaled, Y_train)\n",
    "Y_pred = RandomForestModel.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest has a really hight accuracy, but not as high as the k-nearest neighbour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122217104253032\n",
      "[[4507  488]\n",
      " [ 735  783]]\n"
     ]
    }
   ],
   "source": [
    "# Extremly Random Forest (a.k.a. Extra trees) package\n",
    "\n",
    "ExtremeRandomForest = ExtraTreesClassifier(random_state=0)\n",
    "ExtremeRandomForestModel = ExtremeRandomForest.fit(X_trainScaled, Y_train)\n",
    "Y_pred = ExtremeRandomForestModel.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one even lower than the one we tried earlier, but has a good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Other Models\n",
    "Now we test some other models that also exists. \n",
    "We do this to get even an higher accuracy than the k-nearest neighbour with 82%.\n",
    "\n",
    "* Linear Discriminant Analysis\n",
    "* Quadratic Discriminant Analysis\n",
    "* Logistic Regression Classifier\n",
    "* Multinomial Logistic Regression Classification\n",
    "* Adaptive Boosting\n",
    "* Gradient Boosting\n",
    "* Histogram Gradient Boosting\n",
    "* XGBoost\n",
    "* Stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Discriminant Analysis\n",
      "Accuracy score:  0.7557193305696299\n",
      "Confusion matrix:  [[4827  168]\n",
      " [1423   95]]\n",
      "\n",
      "Quadratic Discriminant Analysis\n",
      "\n",
      "Logistic Regression Classification\n",
      "Accuracy score:  0.7560264087210194\n",
      "Confusion matrix:  [[4813  182]\n",
      " [1407  111]]\n",
      "\n",
      "Multinomial Logistic Regression Classification\n",
      "Accuracy score:  0.7560264087210194\n",
      "Confusion matrix:  [[4813  182]\n",
      " [1407  111]]\n",
      "\n",
      "AdaBoost\n",
      "Accuracy score:  0.8281897742975587\n",
      "Confusion matrix:  [[4563  432]\n",
      " [ 687  831]]\n",
      "\n",
      "Gradient Boosting\n",
      "Accuracy score:  0.8321817902656226\n",
      "Confusion matrix:  [[4581  414]\n",
      " [ 679  839]]\n",
      "\n",
      "XGBoost\n",
      "Accuracy score:  0.8341777982496545\n",
      "Confusion matrix:  [[4566  429]\n",
      " [ 651  867]]\n",
      "\n",
      "Stacking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7945647167204053\n",
      "Confusion matrix:  [[4570  425]\n",
      " [ 913  605]]\n"
     ]
    }
   ],
   "source": [
    "# code to create the models, fit the data, and show its accuracy score (the confusion matrix is here optional).\n",
    "# make sure to print some text between to indicate which result belongs to which model.\n",
    "print(\"\\nLinear Discriminant Analysis\")\n",
    "LinearDiscriminant = LinearDiscriminantAnalysis()\n",
    "LinearDiscriminantModel=LinearDiscriminant.fit(X_trainScaled, Y_train)\n",
    "Y_pred = LinearDiscriminantModel.predict(X_testScaled)\n",
    "print(\"Accuracy score: \",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Confusion matrix: \",confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(\"\\nQuadratic Discriminant Analysis\")\n",
    "QuadraticDiscriminant = QuadraticDiscriminantAnalysis()\n",
    "QuadraticDiscriminantModel=QuadraticDiscriminant.fit(X_trainScaled, Y_train)\n",
    "Y_pred= QuadraticDiscriminantModel.predict(X_testScaled)\n",
    "\n",
    "print(\"\\nLogistic Regression Classification\")\n",
    "LogisticRegress = LogisticRegression()\n",
    "LogisticRegressionModel = LogisticRegress.fit(X_trainScaled, Y_train)\n",
    "Y_pred = LogisticRegressionModel.predict(X_testScaled)\n",
    "print(\"Accuracy score: \",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Confusion matrix: \",confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(\"\\nMultinomial Logistic Regression Classification\")\n",
    "LogisticRegressionML = LogisticRegression(multi_class='multinomial')\n",
    "LogisticRegressionMLModel = LogisticRegressionML.fit(X_trainScaled, Y_train)\n",
    "Y_pred = LogisticRegressionMLModel.predict(X_testScaled)\n",
    "print(\"Accuracy score: \",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Confusion matrix: \",confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(\"\\nAdaBoost\")\n",
    "adaBoost = AdaBoostClassifier(random_state=0)\n",
    "adaBoostModel = adaBoost.fit(X_trainScaled, Y_train)\n",
    "Y_pred = adaBoostModel.predict(X_testScaled)\n",
    "print(\"Accuracy score: \",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Confusion matrix: \",confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(\"\\nGradient Boosting\")\n",
    "gradientBoost = GradientBoostingClassifier(random_state=0)\n",
    "gradientBoostModel = gradientBoost.fit(X_trainScaled, Y_train)\n",
    "Y_pred = gradientBoostModel.predict(X_testScaled)\n",
    "print(\"Accuracy score: \",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Confusion matrix: \",confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(\"\\nXGBoost\")\n",
    "XGboost = HistGradientBoostingClassifier(random_state=0)\n",
    "XGboostModel = XGboost.fit(X_trainScaled, Y_train)\n",
    "Y_pred = XGboostModel.predict(X_testScaled)\n",
    "print(\"Accuracy score: \",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Confusion matrix: \",confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(\"\\nStacking\")\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=1, random_state=80)),\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "                          LinearSVC(random_state=80)))]\n",
    "\n",
    "stackCl = StackingClassifier(estimators=estimators, final_estimator = LogisticRegression())\n",
    "stackCl.fit(X_trainScaled,Y_train)\n",
    "Y_pred = stackCl.predict(X_testScaled)\n",
    "print(\"Accuracy score: \",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Confusion matrix: \",confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 models that outperform the k-nearest neighbour. This is Adaboost with <b>82.81%</b> accuracy, gradient boosting with  <b>83.21% </b> accuracy and XGboost with  <b>83,41% </b> accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
